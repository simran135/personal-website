---
# An instance of the Experience widget.
# Documentation: https://wowchemy.com/docs/page-builder/
widget: experience

# This file represents a page section.
headless: true

# Order that this section appears on the page.
weight: 40

title: Experience
subtitle:

# Date format for experience
#   Refer to https://wowchemy.com/docs/customization/#date-format
date_format: Jan 2006

# Experiences.
#   Add/remove as many `experience` items below as you like.
#   Required fields are `title`, `company`, and `date_start`.
#   Leave `date_end` empty if it's your current employer.
#   Begin multi-line descriptions with YAML's `|2-` multi-line prefix.
experience:
  - title: Research Intern
    company: Abridge INC
    company_url: 'https://www.abridge.com/'
    location: Pittsburgh, PA
    date_start: '2021-01-01'
    date_end: '2021-08-06'
    description: Implementing model frameworks to run experiments to boost symptom classification performance based on doctor patient transcripts
  
  - title: Undergraduate Researcher
    company: ACMI Lab, Carnegie Mellon University
    company_url: 'https://acmilab.org/'
    location: Pittsburgh, PA
    date_start: '2019-05-01'
    date_end: ''
    description: Are Perceptually-Concordant Adversarial Attacks a General Property of Robust Classifiers? NeurIPS 2019 Poster Presenter (paper accepted at Science Meets Engineering of Deep Learning Workshop).Investigated targeted adversarial attacks against a robust classifier trained under randomized smoothing. Our research suggests perceptually-aligned gradients may be a general property of robust classifiers (not just adversarially trained classifiers). Currently investigating the effect of learning rate on generalization ability of models trained via stochastic gradient descent and full-batch gradient descent

  - title: Undergraduate Researcher
    company: ACMI Lab, Carnegie Mellon University (In collaboration with Locus and SAGE Lab)
    company_url: ''
    location: Pittsburgh, PA
    date_start: '2020-06-01'
    date_end: '2020-08-31'
    description: Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability. Published as a conference paper at ICLR 2021; Accepted for Poster Presentation at NeurIPS OPT2020 Workshop. Empirically demonstrated that full-batch gradient descent on neural network training objectives typically operates in a regime we call the Edge of Stability. Since the behavior of the train loss Hessian is inconsistent with several widespread presumptions in the field of optimization, our findings raise questions as to whether these presumptions are relevant to neural network training.

  - title: Head Teaching assistant for 15281 Artificial Intelligence Representation & Problem Solving
    company: Carnegie Mellon University
    location: Pittsburgh, PA
    date_start: '2020-01-01'
    date_end: ''
    description: (Head TA since January 2021) lead multiple weekly recitations of 30 students; develop assignments, recitations, and course notes; hold weekly office hours.
 
  - title: Teaching Assistant for 10301/10601 Introduction to Machine Learning (Undergraduate and Graduate Level)
    company: Carnegie Mellon University
    location: Pittsburgh, PA
    date_start: '2020-05-01'
    date_end: '2020-08-01'
    description:  lead weekly recitations of 30 students; develop assignments and recitations; hold weekly     office hours

design:
  columns: '2'
---
